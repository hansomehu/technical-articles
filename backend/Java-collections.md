---
layout: post
title: "Java Collections"
permalink: /java-collections
---

Java集合框架的核心知识



Java中的集合框架的顶级父类（**接口**）就两个，一个Map一个Collection；到底说就是一类是**KV键值对**结构和一类是**线性结构**

![image-20220512195238265](https://hansomehu-picgo.oss-cn-hangzhou.aliyuncs.com/typora/image-20220512195238265.png)



#### ArrayList

<img src="https://hansomehu-picgo.oss-cn-hangzhou.aliyuncs.com/typora/image-20220414211522013.png" alt="image-20220414211522013" style="zoom:25%;" />

首先底层结构是Object数组，它是顺序容器，即元素存放的数据与放进去的顺序相同。关于容量限制，只有对存入元素个数的限制。每当向数组中添加元素时，都要去检查添加后元素的个数是否会超出当前数组的长度，如果超出，数组将会进行扩容，以满足添加数据的需求。



##### 扩容

扩容的开销较大，不建议让数组根据业务情况来自动扩容，推荐在业务进行之前根据需要手动扩容。

<u>手动扩容的两个办法：</u>

1. 通过**构造函数**传输minCapacity 
2. 调用public方法**ensureCapacity(int minCapacity)** 传入容量参数进行手动扩容，其内部实现最后调的是**grow( )**方法

<u>自动扩容：</u>

每次插入元素时会先检查该操作会不会超过容量限制，如果会则触发自动扩容机制，调用ensureCapacity(int minCapacity)进行扩容操作。每次扩容**1.5倍**。

自动扩容的机制是新建一个1.5倍大小的新数组，再将老数组中的元素拷贝过去，开销较大。因此，推荐在频繁插入大量数据前先根据预算手动将数组扩容至合适大小，以减少自动扩容带来的开销。



##### ArrayList的fail-fast（快速失败）机制

简单讲这种机制就是改了就报错，java.util包下的类都是 采用这种机制

ArrayList也采用了快速失败的机制，通过记录**modCount**参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历

还有个机制叫做**安全失败（fail—safe）**：pull一个分支，改了也不能push回主分支



#### HashMap

<img src="https://hansomehu-picgo.oss-cn-hangzhou.aliyuncs.com/typora/image-20220512203930375.png" alt="image-20220512203930375" style="zoom:33%;" />

JDK1.8以后HashMap的实现采用了**数组+链表+红黑树，**在1.7采用的冲突链表这种方式在大量数据的情况下查找的开销较大

当链表中的元素达到了 **8 个**时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)

有两个参数可以影响HashMap的性能: **初始容量**(inital capacity)和**负载系数**(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过**capacity*load_factor**时，容器将自动扩容并重新哈希，每次扩容后的大小为原来的**2倍**

对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数，采用new HashMap(int **initialCapacity**) 初始化



**HashSet**

基于HashMap进行了一次包装，加入了重复元素检测



##### LinkedHashMap

LinkedHashMap是HashMap的直接子类，二者唯一的区别是LinkedHashMap在HashMap的基础上，采用**双向链表(doubly-linked list)**的形式将所有entry连接起来，这样是为**保证元素的迭代顺序跟插入顺序相同**



**WeakHashMap**

我们都知道Java中内存是通过GC自动管理的，GC会在程序运行过程中自动判断哪些对象是可以被回收的，并在合适的时机进行内存释放。GC判断某个对象是否可被回收的依据是，**是否有有效的引用指向该对象**。如果没有有效引用指向该对象(基本意味着不存在访问该对象的方式)，那么该对象就是可回收的。这里的**有效引用** 并不包括**弱引用**。也就是说，**虽然弱引用可以用来访问对象，但进行垃圾回收时弱引用并不会被考虑在内，仅有弱引用指向的对象仍然会被GC回收**。



**解决hash冲突的办法有哪些？HashMap用的哪种**

解决Hash冲突方法有:开放地址法、再哈希法、链地址法（拉链法）、建立公共溢出区。HashMap中采用的是**链地址法** 。

1. 开放地址法也称为`再散列法`，基本思想就是，如果`p=H(key)`出现冲突时，则以`p`为基础，再次hash，`p1=H(p)`,如果p1再次出现冲突，则以p1为基础，以此类推，直到找到一个不冲突的哈希地址`pi`。 因此开放地址法所需要的hash表的长度要大于等于所需要存放的元素，而且因为存在再次hash，所以`只能在删除的节点上做标记，而不能真正删除节点。

2. 再哈希法(双重散列，多重散列)，提供多个不同的hash函数，当`R1=H1(key1)`发生冲突时，再计算`R2=H2(key1)`，直到没有冲突为止。 这样做虽然不易产生堆集，但增加了计算的时间。

3. <u>链地址法(拉链法)，</u>将哈希值相同的元素构成一个同义词的单链表,并将单链表的头指针存放在哈希表的第i个单元中，查找、插入和删除主要在同义词链表中进行。链表法适用于经常进行插入和删除的情况。

4. 建立公共溢出区，将哈希表分为公共表和溢出表，当溢出发生时，将所有溢出数据统一放到溢出区。



**HashMap为什么线程不安全**

1. 多线程下**扩容死循环**。JDK1.7中的 HashMap 使用头插法插入元素，在多线程的环境下，扩容的时候有可能导致环形链表的出现，形成死循环。因此，JDK1.8使用尾插法插入元素，在扩容时会**保持链表元素原本的顺序**，不会出现环形链表的问题。

   头插法在rehash之后要把原链表元素收集起来然后分配到不同的table位上去，在这个过程中如果是多线程的话，在线程1被挂起之后，线程2可能会改变原链表的结构，导致线程1重新执行的时候指针指向错误的元素。一句话解释就是，线程2如果比线程1先完成链表的rehash，由于是头插法，链表的顺序会倒过来，当线程1 回来的时候它的引用被倒置了，也就是原本的pre指针指向了下一个元素，而next指针指向的却是上一个元素

   或者这么来解释，hashmap对应的**物理存储**一次只能被一个线程操作，而且线程是交替执行的。那么线程ta执行了一半交给了线程tb，tb可能会改变链表的关联顺序，ta回来的时候原本的链表顺序已经被打乱但是ta还是按照原计划执行

2. 多线程的put可能导致**元素的丢失**。多线程同时执行 put 操作，如果计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致元素的丢失。此问题在JDK 1.7和 JDK 1.8 中都存在

3. put和get并发时，可能导致**get为null**。线程1执行put时，因为元素个数超出threshold而导致rehash，线程2此时执行get，有可能导致这个问题。此问题在JDK 1.7和 JDK 1.8 中都存在



**ConcurrentHashMap**

参考 Java - JUC

什么是ConcurrentHashMap的并发度？就是同一时刻多少线程能同时对ConcurrentHashMap写。jdk1.7当中由于锁的级别是Segment且Segment的数量固定为16个，则并发度就是16。在jdk1.8之后，锁的粒度是数组的元素个数，并且数组是可以扩容的，那么理论上没有上限，但是受制于硬件还是emmm......



#### LinkedList

这个结构的包含item、pre、next

当我们涉及到大量的修改元素的时候使用LinkedList，而只是新增和删除、查找操作为多的话使用ArrayList更加高效些